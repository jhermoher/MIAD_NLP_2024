{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![image info](https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/images/banner_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto 1 - Predicción de precios de vehículos usados\n",
    "\n",
    "En este proyecto podrán poner en práctica sus conocimientos sobre modelos predictivos basados en árboles y ensambles, y sobre la disponibilización de modelos. Para su desasrrollo tengan en cuenta las instrucciones dadas en la \"Guía del proyecto 1: Predicción de precios de vehículos usados\".\n",
    "\n",
    "**Entrega**: La entrega del proyecto deberán realizarla durante la semana 4. Sin embargo, es importante que avancen en la semana 3 en el modelado del problema y en parte del informe, tal y como se les indicó en la guía.\n",
    "\n",
    "Para hacer la entrega, deberán adjuntar el informe autocontenido en PDF a la actividad de entrega del proyecto que encontrarán en la semana 4, y subir el archivo de predicciones a la [competencia de Kaggle](https://www.kaggle.com/t/b8be43cf89c540bfaf3831f2c8506614)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datos para la predicción de precios de vehículos usados\n",
    "\n",
    "En este proyecto se usará el conjunto de datos de Car Listings de Kaggle, donde cada observación representa el precio de un automóvil teniendo en cuenta distintas variables como: año, marca, modelo, entre otras. El objetivo es predecir el precio del automóvil. Para más detalles puede visitar el siguiente enlace: [datos](https://www.kaggle.com/jpayne/852k-used-car-listings)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplo predicción conjunto de test para envío a Kaggle\n",
    "\n",
    "En esta sección encontrarán el formato en el que deben guardar los resultados de la predicción para que puedan subirlos a la competencia en Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importación librerías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('darkgrid')\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "from sklearn.model_selection import cross_val_score \n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos de archivo .csv\n",
    "dataTraining = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/dataTrain_carListings.zip')\n",
    "dataTesting = pd.read_csv('https://raw.githubusercontent.com/davidzarruk/MIAD_ML_NLP_2023/main/datasets/dataTest_carListings.zip', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de entrenamiento\n",
    "print(dataTraining.info())\n",
    "dataTraining.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización datos de test\n",
    "print(dataTesting.info())\n",
    "dataTesting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grafica_distribucion(df: pd.DataFrame):\n",
    "    '''\n",
    "    '''\n",
    "    df_num = df.select_dtypes(exclude=[object]).copy()\n",
    "    df_cat = df.select_dtypes(include=[object]).copy()\n",
    "\n",
    "    var_num = df_num.columns.to_list()\n",
    "    col = len(var_num)\n",
    "    fig, axes = plt.subplots (1,col,figsize = (18,4))\n",
    "    fig.suptitle('DISTRIBUCIÓN DE VARIABLES NUMERICAS')\n",
    "\n",
    "    for i,j in enumerate (var_num):\n",
    "        data = df_num[j]\n",
    "        axes[i].hist(data,bins = 50,color = \"green\",alpha = 0.65, rwidth = 0.85);\n",
    "        axes[i].set_xlabel(f'{j}')\n",
    "        axes[1].set_ylabel('cantidad')\n",
    "    \n",
    "    sns.pairplot(df);\n",
    "    \n",
    "\n",
    "    var_cat= df_cat.columns.to_list()\n",
    "    col = len(var_cat)\n",
    "    fig, axes = plt.subplots (col,1,figsize = (17,7))\n",
    "    fig.suptitle('DISTRIBUCIÓN DE VARIABLES CATAGÓRICAS')\n",
    "\n",
    "    for i, j in enumerate(var_cat):\n",
    "        data = df_cat[j].value_counts()\n",
    "        sns.countplot(x=j, data=df_cat, ax=axes[i]);\n",
    "        axes[i].set_xlabel(f'{j}')\n",
    "        axes[i].set_ylabel('cantidad')\n",
    "        axes[i].tick_params(axis='x', rotation=45,labelsize=7)\n",
    "\n",
    "    return\n",
    "\n",
    "def stats(df:pd.DataFrame):\n",
    "    '''\n",
    "    '''\n",
    "    df_num = df.select_dtypes(exclude=[object]).copy()\n",
    "    df_cat = df.select_dtypes(include=[object]).copy()\n",
    "\n",
    "    for i,j in enumerate (df_cat.columns.tolist()):\n",
    "        print(f'Variable: {j}')\n",
    "        print(f'Cantidad de clases: {df_cat[j].nunique()}')\n",
    "        print(f'Top 10 de las clases: {Counter(df_cat[j]).most_common(10)}')\n",
    "        print('------------------------------------')\n",
    "        \n",
    "    return df_num.describe().T \n",
    "\n",
    "def remover(df, columns, threshold=3):\n",
    "    '''\n",
    "    '''\n",
    "    df_no_outliers = pd.DataFrame()\n",
    "    \n",
    "    for column in columns:\n",
    "        z_scores = np.abs((df[column] - df[column].mean()) / df[column].std())\n",
    "        df_filtered = df[z_scores <= threshold]\n",
    "        df_no_outliers = pd.concat([df_no_outliers, df_filtered], ignore_index=True)\n",
    "    \n",
    "    return df_no_outliers\n",
    "\n",
    "def metrics(test,predd):\n",
    "      RMSE = np.sqrt(mean_squared_error(test,predd))\n",
    "      return print(f\"La métrica de evaluación del modelo regresión es:\\nRMSE : {RMSE:,.6f}\")\n",
    "\n",
    "def metrics_CV(model,X,y):\n",
    "      mse_scores = cross_val_score(model, X, y, cv=5, scoring='neg_mean_squared_error')\n",
    "      mean_mse = -np.mean(mse_scores)\n",
    "      RMSE = np.sqrt(mean_mse)\n",
    "      return RMSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats(dataTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining['Make'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grafica_distribucion(dataTraining)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining_org = dataTraining.copy()\n",
    "dataTraining_org['Make-Model'] = dataTraining_org['Make'] + '-' + dataTraining_org['Model']\n",
    "dataTraining_org.drop(columns=['Make', 'Model'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataTraining_org = remover(dataTraining_org, ['Mileage'], threshold=100)\n",
    "#dataTraining_org['Price'] = np.log(dataTraining_org['Price'])  \n",
    "sns.pairplot(dataTraining_org);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataTraining_org.drop(['Price'], axis=1)\n",
    "y = dataTraining_org['Price']\n",
    "\n",
    "data_num = X.select_dtypes(exclude=[object]).copy()\n",
    "data_cat = X.select_dtypes(include=[object]).copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_num_scaled = scaler.fit_transform(data_num)\n",
    "\n",
    "#decomposer = PLSRegression(n_components=2).fit(data_num_scaled,y)\n",
    "#data_num_pls = decomposer.transform(data_num_scaled)\n",
    "\n",
    "decomposer = PCA(n_components=2).fit(data_num_scaled)\n",
    "data_num_pca = decomposer.transform(data_num_scaled)\n",
    "\n",
    "for i in data_cat.columns:\n",
    "    data_cat[i] = data_cat[i].astype('category')\n",
    "\n",
    "data_cat_encoded = pd.get_dummies(data_cat,columns=data_cat.columns, drop_first=True)\n",
    "#encoder = OneHotEncoder(handle_unknown='ignore', drop='first').fit(data_cat)\n",
    "#data_cat_encoded = encoder.transform(data_cat).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_training = np.concatenate((data_num_pca, data_cat_encoded), axis=1)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_training, y, test_size=0.20, random_state=42)\n",
    "\n",
    "X_train = pd.DataFrame(X_train, columns=['PCA1', 'PCA2'] + data_cat_encoded.columns.tolist())\n",
    "X_test = pd.DataFrame(X_test, columns=['PCA1', 'PCA2'] + data_cat_encoded.columns.tolist())\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_depth = [int(x) for x in np.linspace(1,10,10)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'learning_rate': 0.5,\n",
    "          'n_estimators': 500}   \n",
    "\n",
    "for depth in range_depth:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, max_depth=depth, **params)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "depth = range_depth[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {depth}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_leaves = [int(x) for x in np.linspace(1, 50, 50)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'learning_rate': 0.5,\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': depth}   \n",
    "\n",
    "for leaves in range_leaves:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, max_leaves=leaves, **params)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "leaves = range_leaves[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {leaves}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#range_gamma= [float(x) for x in np.linspace(0, 1.0, 50)]\n",
    "range_gamma= [0.001,0.1]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'learning_rate': 15,\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': depth,\n",
    "          'max_leaves': leaves} \n",
    "\n",
    "for gamma_ in range_gamma:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, gamma=gamma_, **params)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "gamma_ = range_gamma[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {gamma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_subsample = [float(x) for x in np.linspace(0, 1.0, 50)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'learning_rate': 15,\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': depth,\n",
    "          'max_leaves': leaves,\n",
    "          'gamma': gamma_}   \n",
    "\n",
    "for subsample in range_subsample:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, subsample=subsample, **params)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "subsample = range_subsample[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {subsample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_colsample = [float(x) for x in np.linspace(0, 1.0, 50)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'learning_rate': 15,\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': depth,\n",
    "          'gamma': gamma_,\n",
    "          'max_leaves': leaves,\n",
    "          'subsample': subsample}   \n",
    "\n",
    "for colsample in range_colsample:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, colsample_bytree=colsample, **params)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "colsample = range_colsample[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {colsample}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_regularization = [float(x) for x in np.linspace(0, 5, 100)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'learning_rate': 15,\n",
    "          'n_estimators': 500,\n",
    "          'max_depth': depth,\n",
    "          'gamma': gamma_,\n",
    "          'max_leaves': leaves,\n",
    "          'subsample': subsample,\n",
    "          'colsample_bytree': colsample}  \n",
    "\n",
    "for regul in range_regularization:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, reg_alpha=regul, **params)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "regul = range_regularization[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {regul}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_learning = [float(x) for x in np.linspace(0.01, 0.1, 100)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': depth,\n",
    "          'gamma': gamma_,\n",
    "          'max_leaves': leaves,\n",
    "          'subsample': subsample,\n",
    "          'colsample_bytree': colsample,\n",
    "          'reg_alpha': regul}  \n",
    "\n",
    "for learning in range_learning:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, learning_rate=learning)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "learning = range_learning[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {learning}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_estimators = [int(x) for x in np.linspace(150, 350, 100)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'max_depth': depth,\n",
    "          'gamma': gamma_,\n",
    "          'max_leaves': leaves,\n",
    "          'subsample': subsample,\n",
    "          'colsample_bytree': colsample,\n",
    "          'reg_alpha': regul,\n",
    "          'learning_rate': learning}  \n",
    "\n",
    "for estimator in range_estimators:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, n_estimators=estimator, learning_rate=learning)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "estimators = range_estimators[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {estimators}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_gamma= [float(x) for x in np.linspace(0, 1.0, 50)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'max_depth': depth,\n",
    "          'max_leaves': leaves,\n",
    "          'subsample': subsample,\n",
    "          'colsample_bytree': colsample,\n",
    "          'reg_alpha': regul,\n",
    "          'learning_rate': learning,\n",
    "          'n_estimators': estimators}  \n",
    "\n",
    "for gamma_ in range_gamma:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, gamma=gamma_, **params)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "gamma_ = range_gamma[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {gamma_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "range_leaves = [int(x) for x in np.linspace(1, 50, 50)]\n",
    "RMSE_scores = []\n",
    "\n",
    "params = {'max_depth': depth,\n",
    "          'subsample': subsample,\n",
    "          'colsample_bytree': colsample,\n",
    "          'reg_alpha': regul,\n",
    "          'learning_rate': learning,\n",
    "          'n_estimators': estimators,\n",
    "          'gamma': gamma_}   \n",
    "\n",
    "for leaves in range_leaves:\n",
    "    model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, max_leaves=leaves, **params)\n",
    "    model_xgb.fit(X_train, y_train)\n",
    "    prediction = model_xgb.predict(X_test)\n",
    "    RMSE_scores.append(np.sqrt(mean_squared_error(y_test, prediction)))\n",
    "\n",
    "leaves = range_leaves[np.argmin(RMSE_scores)]\n",
    "print(f'El valor óptimo es: {leaves}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'learning_rate': 0.9252525252525252,\n",
    "           'n_estimators': 198,\n",
    "           'max_depth': 6,\n",
    "           'max_leaves': 37, \n",
    "           'subsample': 1.0, \n",
    "           'colsample_bytree': 1.0,\n",
    "           'gamma': 0.0, \n",
    "           'reg_alpha': 2.2222222222222223}\n",
    "\n",
    "model_xgb = XGBRegressor(objective ='reg:squarederror', eval_metric='rmse',random_state=42, n_jobs=-1, ** params)\n",
    "\n",
    "model_xgb.fit(X_train, y_train)\n",
    "prediction = model_xgb.predict(X_test)\n",
    "\n",
    "metrics(y_test, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### with the complete set of data (threshold = 100)\n",
    "\n",
    "\n",
    "\n",
    "#### with the complete set of data (threshold = 30)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_xgb.fit(X_training, y)\n",
    "\n",
    "data_num_ = dataTesting.select_dtypes(exclude=[object]).copy()\n",
    "data_cat_ = dataTesting.select_dtypes(include=[object]).copy()\n",
    "\n",
    "\n",
    "\n",
    "data_num_scaled_ = scaler.transform(data_num_)\n",
    "\n",
    "data_num_pca_ = decomposer.transform(data_num_scaled_)\n",
    "\n",
    "for i in data_cat_.columns:\n",
    "    data_cat_[i] = data_cat_[i].astype('category')\n",
    "\n",
    "data_cat_encoded_ = pd.get_dummies(data_cat_,columns=data_cat_.columns, drop_first=True)\n",
    "#data_cat_encoded_ = encoder.transform(data_cat_).toarray()\n",
    "\n",
    "X_testing = np.concatenate((data_num_pca_, data_cat_encoded_), axis=1)\n",
    "X_testing = pd.DataFrame(X_testing, columns=['PCA1', 'PCA2'] + data_cat_encoded_.columns.tolist()) \n",
    "X_testing['Make_Freightliner'] = 0\n",
    "X_testing = X_testing[X_train.columns.tolist()]\n",
    "\n",
    "y_prediction = model_xgb.predict(X_testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predd = pd.DataFrame(y_prediction, columns=['Price'])\n",
    "y_predd.to_csv('20240422_woo_pca_comp_.csv', index_label='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción del conjunto de test - acá se genera un número aleatorio como ejemplo\n",
    "np.random.seed(42)\n",
    "y_pred = pd.DataFrame(np.random.rand(dataTesting.shape[0]) * 75000 + 5000, index=dataTesting.index, columns=['Price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar predicciones en formato exigido en la competencia de kaggle\n",
    "y_pred.to_csv('test_submission.csv', index_label='ID')\n",
    "y_pred.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
